{
    "batch_size": 32,
    "num_batches_trained_on": 501,
    "learning_rate": 0.001,
    "input_size": 10240,
    "reg_lambda": 1.2616612944575138,
    "hookpoint": "gpt_neox.layers.22.mlp.act"
}