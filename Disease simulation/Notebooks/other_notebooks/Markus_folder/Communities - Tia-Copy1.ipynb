{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "\n",
    "#from infomap import infomap\n",
    "#from cdlib import algorithms\n",
    "#import igraph as ig\n",
    "#import leidenalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-apache",
   "metadata": {},
   "source": [
    "# Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../Data/final_cool_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(row['ORIGIN'], row['DEST'], {'weight': row['PASSENGERS']}) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = sorted(G.degree, key=lambda x: x[1], reverse=True) # not considering weights\n",
    "degrees[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-pressing",
   "metadata": {},
   "source": [
    "# Describing our network\n",
    "- Degree distribution\n",
    "- Clustring coefficient (global + local)\n",
    "- Diameter + average path length (small diameter - everyone is reachable. Large diameter - traversal might be impossible)\n",
    "\n",
    "Show that our graph is dense, tightly connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-dubai",
   "metadata": {},
   "source": [
    "# Possible measures of importance / centrality\n",
    "\n",
    "Figure out which nodes / edges are central and peripheral. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-canvas",
   "metadata": {},
   "source": [
    "## A) Node measures \n",
    "### _Degree-based_: Degree Centrality\n",
    "The number of links incident upon a node. The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). Since we have a directed network, we should define both an indegree and outdegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing in-degree for nodes in G\n",
    "sorted_in_degree = sorted(nx.in_degree_centrality(G).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Selecting 10 highest ranking nodes\n",
    "sorted_in_degree[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing out-degree for nodes in G\n",
    "sorted_out_degree = sorted(nx.out_degree_centrality(G).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Selecting 10 highest ranking nodes\n",
    "sorted_out_degree[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-australian",
   "metadata": {},
   "source": [
    "### _Degree-based_: Eigenvector centrailty (eigencentrality)\n",
    " - Lecture 2\n",
    " \n",
    "Assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes.\n",
    "\n",
    "Using the adjacency matrix to find eigenvector centrality: In general, there will be many different eigenvalues \n",
    "$\\lambda$  for which a non-zero eigenvector solution exists. Since the entries in the adjacency matrix are non-negative, there is a unique largest eigenvalue, which is real and positive, by the Perron–Frobenius theorem. This greatest eigenvalue results in the desired centrality measure. The $v$'th component of the related eigenvector then gives the relative centrality score of the vertex $v$ in the network.\n",
    "\n",
    "Can we use the eigenvectors to discover 'bridges' between clusters?\n",
    "\n",
    "For directed graphs, we can use the Eigen Vector Centrality to evaluate the “importance” of a node (based on the out-degree Eigen Vector) and the “prestige” of a node (through the in-degree Eigen Vector).\n",
    "- A node is considered to be more important if it has out-going links to nodes that in turn have a larger out-degree (i.e., more out-going links).\n",
    "- A node is considered to have a higher “prestige”, if it has in-coming links from nodes that themselves have a larger in-degree (i.e., more in-coming links).\n",
    "\n",
    "**OBS**: Is it problematic for directed graphs?? Eigenvector centrality will not take zero in-degree nodes into account in directed graphs. \n",
    "_Example_: A new research paper is published and it references a handful of existing papers. It would not contribute to any of those referenced papers in this citation network because it is not cited by any other papers and has zero eigenvector centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-alfred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prompt-orlando",
   "metadata": {},
   "source": [
    "### _Shortest-path-based_: Closeness centrailty\n",
    "Is a measure of centrality in a network, calculated as the reciprocal of the sum of the length of the shortest paths between the node and all other nodes in the graph. The more central a node is, the closer it is to all other nodes.\n",
    "\n",
    "We must consider taking distances _from_ or _to_ all other nodes, as it can produce very different results in directed graphs (e.g. an airport can have a high closeness centrality from outgoing routes, but low closeness centrality from incoming routes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-assist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computing inward distance to a node, using edge weights\n",
    "sorted_closeness_centraility = sorted(nx.closeness_centrality(G, distance='weights', wf_improved=False).items(), \n",
    "                                      key=lambda x: x[1], reverse=True) # wf=True only for disconnected graphs\n",
    "\n",
    "# Selecting 10 highest ranking nodes\n",
    "sorted_closeness_centraility[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing outward distance to a node, using edge weights\n",
    "sorted_closeness_centraility = sorted(nx.closeness_centrality(G.reverse(), distance='weights', wf_improved=False).items(), \n",
    "                                      key=lambda x: x[1], reverse=True) # G.reverse() = outward distance, directions reversed\n",
    "\n",
    "# Selecting 10 highest ranking nodes\n",
    "sorted_closeness_centraility[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-substance",
   "metadata": {},
   "source": [
    "### _Shortest-path-based_: Betweenness centrailty (node)  \n",
    "- Lecture 3\n",
    "\n",
    "Quantifies the number of times a _node_ acts as a bridge along the shortest path between two other nodes. In his conception, nodes that have a high probability to occur on a randomly chosen shortest path between two randomly chosen vertices have a high betweenness. The measure is related to a network's connectivity - high betweenness nodes have the potential to disconnect graphs if removed.\n",
    "\n",
    "(Find out which algorithm to use for directed, weighted graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove edges with weight zero (or use graph with +1 values, Markus)\n",
    "G_nonzero = G.copy()\n",
    "to_remove = [(a,b) for a, b, attrs in G.edges(data=True) if attrs[\"weight\"] <= 0.0]\n",
    "G_nonzero.remove_edges_from(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing betweenness centrality for nodes in G\n",
    "betweenness = sorted(nx.betweenness_centrality(G_nonzero, normalized=True, weight='weights', endpoints=False, seed=0).items(), \n",
    "               key=lambda x: x[1], reverse=True) # set seed to make reproducible \n",
    "\n",
    "# Selecting 10 highest ranking nodes\n",
    "betweenness[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-compiler",
   "metadata": {},
   "source": [
    "### Percolation centrality - Not covered?\n",
    "Specifically measures the importance of nodes in terms of aiding the percolation through the network. It is defined for a given node, at a given time, as the proportion of ‘percolated paths’ that go through that node. A ‘percolated path’ is a shortest path between a pair of nodes, where the source node is percolated (e.g., infected). The target node can be percolated or non-percolated, or in a partially percolated state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-fossil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "checked-employment",
   "metadata": {},
   "source": [
    "### Local Clustering coefficcient\n",
    "The global version gives an overall indication of the clustering in the network, whereas the local gives an indication of the embeddedness of single nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-likelihood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pacific-affiliate",
   "metadata": {},
   "source": [
    "## B) Edge measures \n",
    "\n",
    "#### Betweenness centrailty (edge)\n",
    "The number of the shortest paths to go through an _edge_ in a graph or network (Girvan and Newman). An edge with a high edge betweenness centrality score represents a bridge-like connector between two parts of a network (as with node betweenness centrailty), where the removal may affect the 'communication' between many pairs of nodes through the shortest paths between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing betweenness centrality for edges in G\n",
    "edge_betweenness = [(k, v) for k, v in sorted(nx.edge_betweenness_centrality(G, normalized=True, weight='weights', seed=0).items(), key=lambda item: item[1], reverse=True)]\n",
    "\n",
    "# Selecting 10 highest ranking edges\n",
    "edge_betweenness[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-correlation",
   "metadata": {},
   "source": [
    "# Community Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-front",
   "metadata": {},
   "source": [
    "### CD: Girvan-Newman\n",
    "Communities are discovered by iteratively removing the \"most valuable\" edges of the graph. This value is based on the edge betweenness centrality (the number of shortest paths that pass through an edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = girvan_newman(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = []\n",
    "for com in next(communities):\n",
    "    node_groups.append(list(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no. of communities:', len(node_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = []\n",
    "for node in G:\n",
    "    if node in node_groups[0]:\n",
    "        color_map.append('blue')\n",
    "    elif node in node_groups[1]:\n",
    "        color_map.append('red')\n",
    "    else: \n",
    "        color_map.append('green')  \n",
    "nx.draw(G, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-alexandria",
   "metadata": {},
   "source": [
    "### CD: Label Propagation\n",
    "Each node in the network is first given a unique label; at each iteration, each node is updated by choosing the label which is the most frequent among its neighbors – if multiple choices are possible, one label is picked randomly. The algorithm halts when each node has the label that appears most frequently among its neighbors. \n",
    "\n",
    "The algorithm below is asynchronous: only one node is updated at each iteration without waiting for updates on the remaining nodes. The algorithm is not deterministic. It is probabilistic and the found communities may vary for each different executions.\n",
    "\n",
    "**Asynchronous vs. Synchronous**\n",
    "- Asynchronous model: Label propagation step is performed **sequentailly** on all nodes. Updating where $C_x(t)=f(C_{xi1}(t),...,C_{xim}(t),C_{xi}(m+1)(t−1),...,C_{xik}(t−1))$ and $x_{i1},...,x_{im}$ are neighbors of $x$ that have already been updated in the current iteration while $x_i(m+1),...,x_{ik}$ are neighbors that are not yet updated in the current iteration. The order in which all the $n$ nodes in the network are updated at each iteration is chosen randomly\n",
    "- Synchronous model: Label propagation step is performed **in parallel** on all nodes. Each node computes its label at step $i$ based on the label of its neighbors at step $i − 1$.\n",
    "\n",
    "\n",
    "(The semi-synchronous version of this algorithm does not work for directed graphs). \n",
    "\n",
    "\n",
    "\n",
    "The label propagation algorithm can be either synchronous, as presented above, or asynchronous. In the synchronous model (cf. Algorithm 1) each vertex computes its label at\n",
    "\n",
    "\n",
    "**From litterature: https://arxiv.org/pdf/1103.4550.pdf**:\n",
    "\n",
    "The community detection strategy based on a label propagation algorithm (LPA) identifies network partitions by an “epidemic” approach, i.e., it uses the diffusion of information in the network to identify communities => this is why this CD algo could be relevant for our project!\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0378437116301807\n",
    "https://arxiv.org/pdf/0709.2938.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prob = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.community.modularity(G, label_prob, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP_generator(graph, coms, iterations):\n",
    "    '''\n",
    "    Function which compares ...\n",
    "    '''\n",
    "    \n",
    "    #lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(graph, weight='weight', seed=0))\n",
    "    unequal = 0\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(len(coms)):\n",
    "            lp_test = list(nx.community.label_propagation.asyn_lpa_communities(graph, weight='weight')) # don't set seed for this\n",
    "            if (coms[i] ^ lp_test[i]): # there is a difference\n",
    "                unequal += 1\n",
    "            else: # there is no difference\n",
    "                pass\n",
    "    print('All communities are the same:', unequal == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed=0))\n",
    "LP_generator(G, coms, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight'))\n",
    "    print(len(lp_coms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight'))\n",
    "unequal = 0\n",
    "\n",
    "for _ in range(10):\n",
    "    for i in range(len(lp_coms)):\n",
    "        lp_test = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight')) # don't set seed for this\n",
    "        if (lp_coms[i] ^ lp_test[i]): # there is a difference\n",
    "            print('there is a difference')\n",
    "            #unequal += 1\n",
    "        else: # there is no difference\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [{3,2},{4,5}]\n",
    "s2 = [{1,2},{4,5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s1)):\n",
    "    if (s1[i] ^ s2[i]):\n",
    "        print('there is a difference')\n",
    "    else:\n",
    "        print('there is no difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[{1,3},{4,5}],[{3,2},{4,5}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    for j in i:\n",
    "        print(test[0][j].difference(test[1][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed=0))\n",
    "unequal = 0\n",
    "diff_comm = []\n",
    "for _ in range(10):\n",
    "    lp_test = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight'))\n",
    "    # don't set seed for this\n",
    "    if len(lp_coms) == len(lp_test):\n",
    "        for i in range(len(lp_test)):\n",
    "            if (coms[i] ^ lp_test[i]): # there is a difference\n",
    "                unequal += 1\n",
    "            else: # there is no difference\n",
    "                    pass\n",
    "    else:\n",
    "        diff_comm.append(len(lp_test) - len(lp_coms))\n",
    "print(Counter(diff_comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'AFK': {0: 0, 1: 2, 2: 1, 3: 1, 4: 1}}\n",
    "\n",
    "# for each interation: \n",
    "# re-define communities\n",
    "# check if there are the same amaount of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed=0))\n",
    "counter = 0\n",
    "set_nodes = set(G.nodes())\n",
    "dict_com = dict()\n",
    "for i in lp_coms:\n",
    "    print(i[0])\n",
    "    \n",
    "    #    counter +=1\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight', seed = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of all nodes, adding which community each is in\n",
    "iterations = 20\n",
    "\n",
    "dictresult = dict()\n",
    "list_comm = []\n",
    "for _ in range(iterations):\n",
    "    lp_test = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight')) # don't set seed\n",
    "    for i in G.nodes():\n",
    "        for j in range(len(lp_test)):\n",
    "            if i in lp_test[j]:\n",
    "                dictresult.setdefault(i,[]).append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dict, counting the co-apperance of each airport in a community\n",
    "dict_shared = dict()\n",
    "for i in range(iterations):\n",
    "    for A1 in dictresult.keys():\n",
    "        for A2 in dictresult.keys():\n",
    "            if dictresult[A1][i] == dictresult[A2][i]:\n",
    "                dict_shared.setdefault(A1, []).append(A2)\n",
    "\n",
    "dict_nested = dict()\n",
    "for i,j in dict_shared.items():\n",
    "    dict_nested[i] = Counter(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "community1 = []\n",
    "community2 = []\n",
    "community3 = []\n",
    "for key in dict_nested.keys():\n",
    "    if key in dict_nested:\n",
    "        print(key)\n",
    "        for k,v in dict_nested[key].items():\n",
    "            if v == iterations:\n",
    "                community1.append(k)\n",
    "                del dict_nested[k]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    break\n",
    "for key in dict_nested.keys():\n",
    "    print(key)\n",
    "    for k,v in dict_nested[key].items():\n",
    "        if v == iterations:\n",
    "            community2.append(k)\n",
    "            del dict_nested[k]\n",
    "    break\n",
    "for key in dict_nested.keys():\n",
    "    print(key)\n",
    "    for k,v in dict_nested[key].items():\n",
    "        if v == iterations:\n",
    "            community3.append(k)\n",
    "            del dict_nested[k]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_nested.keys():\n",
    "    if key in dict_nested:\n",
    "        print(key)\n",
    "        for k,v in dict_nested[key].items():\n",
    "            if v == iterations:\n",
    "                community1.append(k)\n",
    "                del dict_nested[k]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(community1), len(community2), len(community3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nested.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm1 = []\n",
    "for k,v in dict_nested['BUR'].items():\n",
    "    if v == iterations:\n",
    "        comm1.append(k)\n",
    "    else: \n",
    "        print(k,v)\n",
    "print(comm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_nested['OXR'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = []\n",
    "\n",
    "for node in dict_nested.keys():\n",
    "    #if key in dict_nested:\n",
    "    #print(key)\n",
    "    key_list = []\n",
    "    for k,v in dict_nested[key].items():\n",
    "        if v == iterations:\n",
    "            key_list.append(k)\n",
    "            #print(k)\n",
    "            #del dict_nested[k]\n",
    "    communities.append(key_list)\n",
    "    break\n",
    "\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=20\n",
    "communities = []\n",
    "border_nodes = []\n",
    "node_dict = dict(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes:\n",
    "    if node in node_dict.keys():\n",
    "        #print(node)\n",
    "        key_list = []\n",
    "        border_list = []\n",
    "        \n",
    "        for k,v in dict_nested[node].items():\n",
    "            if v == iterations:\n",
    "                key_list.append(k)\n",
    "                del node_dict[k]\n",
    "#            elif k not in border_nodes:                    \n",
    "#                border_nodes.append(k)\n",
    "            else:\n",
    "                pass\n",
    "        if key_list:\n",
    "            communities.append(key_list)\n",
    "        #if border_list:\n",
    "         #   border_nodes.append(border_list)\n",
    "    \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(node_dict, '\\n')\n",
    "print('Solid communities:', communities)\n",
    "print('\\nBorder:', border_nodes)\n",
    "print('\\n',communities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes:\n",
    "    if node in node_list:\n",
    "        #for node in dict_nested.keys():\n",
    "        #if key in dict_nested:\n",
    "        #print(node)\n",
    "        key_list = []\n",
    "        \n",
    "        for k,v in dict_nested[node].items():\n",
    "            if v == iterations:\n",
    "                key_list.append(k)\n",
    "                #print(k)\n",
    "                node_list.remove(k)\n",
    "    communities.append(key_list)\n",
    "    #print(node_list)\n",
    "    break\n",
    "    \n",
    "print(node_list, '\\n')\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_lp_com(G,iterations): \n",
    "    communities = []\n",
    "    border_nodes = []\n",
    "    \n",
    "    node_dict = dict(G.nodes)\n",
    "    dictresult = dict()\n",
    "    dict_shared = dict()\n",
    "    dict_nested = dict()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        lp_test = list(nx.community.label_propagation.asyn_lpa_communities(G, weight='weight')) # don't set seed\n",
    "        for i in G.nodes():\n",
    "            for j in range(len(lp_test)):\n",
    "                if i in lp_test[j]:\n",
    "                    dictresult.setdefault(i,[]).append(j)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        for A1 in dictresult.keys():\n",
    "            for A2 in dictresult.keys():\n",
    "                if dictresult[A1][i] == dictresult[A2][i]:\n",
    "                    dict_shared.setdefault(A1, []).append(A2)\n",
    "                    \n",
    "    for i,j in dict_shared.items():\n",
    "        dict_nested[i] = Counter(j)\n",
    "\n",
    "    for node in G.nodes:\n",
    "        if node in node_dict.keys():\n",
    "            key_list = []\n",
    "            border_list = []\n",
    "\n",
    "            for k,v in dict_nested[node].items():\n",
    "                if v == iterations:\n",
    "                    key_list.append(k)\n",
    "                    del node_dict[k]\n",
    "                else:\n",
    "                    pass\n",
    "            if key_list:\n",
    "                communities.append(key_list)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = majority_lp_com(G,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nested['HTO'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689166fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = pd.read_json('../../../Data/total.json')\n",
    "\n",
    "coords = coords.T.reset_index()\n",
    "\n",
    "coords_origin = coords.rename(columns = {'index':'ORIGIN',0:'longitude_origin',1:'latitude_origin'})\n",
    "coords_dest = coords.rename(columns = {'index':'DEST',0:'longitude_dest',1:'latitude_dest'})\n",
    "\n",
    "data_filtered_coord = pd.merge(df,coords_origin, on = ['ORIGIN'])\n",
    "\n",
    "data_filtered_coord = pd.merge(data_filtered_coord,coords_dest, on = [\"DEST\"])\n",
    "\n",
    "mask1 = ~data_filtered_coord['ORIGIN'].isin(['SYA','TNK','RBN']) & ~data_filtered_coord['DEST'].isin(['SYA','TNK','RBN'])\n",
    "\n",
    "coords_name_df = pd.DataFrame()\n",
    "coords_name_df['ORIGIN'] = data_filtered_coord[mask1]['ORIGIN']\n",
    "coords_name_df['COORDS'] = list(zip(data_filtered_coord[mask1]['latitude_origin'],data_filtered_coord[mask1]['longitude_origin']))\n",
    "\n",
    "G_coord = nx.DiGraph()\n",
    "\n",
    "pos = dict()\n",
    "for i,j in zip(coords_name_df['ORIGIN'],coords_name_df['COORDS']):\n",
    "    pos[i] = (j[0],j[1])\n",
    "    G_coord.add_node(i)\n",
    "\n",
    "for i,j in zip(data_filtered_coord[mask1]['ORIGIN'],data_filtered_coord[mask1]['DEST']):\n",
    "    G_coord.add_edge(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictresult = dict()\n",
    "list_comm = []\n",
    "for i in G.nodes():\n",
    "    for j in range(len(communities)):\n",
    "        if i in communities[j]:\n",
    "            dictresult.setdefault(i,[]).append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'green', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000','pink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(dictresult, dtype=object)\n",
    "\n",
    "df1 = df1.transpose()\n",
    "\n",
    "df2 = df1.copy()\n",
    "\n",
    "for i in df2.iterrows():\n",
    "    for j in range(len(i[1])):\n",
    "        i[1][j] = colors[i[1][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [df2.loc[node][0] for node in G_coord.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b73b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (300,200))\n",
    "nx.draw(G_coord,pos = pos,with_labels = True,font_color = 'white',node_size = 5000,node_color = col_list,edge_color = 'lightgray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276672b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
