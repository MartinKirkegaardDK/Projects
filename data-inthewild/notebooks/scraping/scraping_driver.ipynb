{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "This notebook represents the skeleton of the developed scraper and all cells have to be ran manually. However, if you'd like to see our ready-to-be-cloud-deployed scraper, check the scraper.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import scraping as f # Custom functions file containing all of the functions needed for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Parameters\n",
    "In this section there are some parameters that we used for scraping. The link represents the category we've decided to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.set_page_load_timeout(500)\n",
    "link = \"https://tasty.co/tag/dinner\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting URLs\n",
    "In this step, we scrape all the links in the recipe category called Dinner as seen in the variable link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_urls(driver,link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Link Queue\n",
    "In this step, we create a link queue, so that in case the scraper breaks, we can continue from the latest scraped link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.create_link_queue('../../data/interim/scraping/links.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Images\n",
    "Here we are scraping the recipe images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_images(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "In this step, we are going into all the recipe links scraped and we are scraping the following:\n",
    "\n",
    "- Ingredients\n",
    "- Nutritional info\n",
    "- Preparation steps\n",
    "- Last edited date\n",
    "- Rating\n",
    "- Tags\n",
    "- Number of comments\n",
    "- Comments\n",
    "\n",
    "NB: This scraping code does not work anymore --- They changed the layout of their website somewhat, so the comments don't scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/interim/scraping/has_scraped.json') as json_file:\n",
    "    links = json.load(json_file)\n",
    "\n",
    "d = dict()\n",
    "for link, has_scaped in links.items():\n",
    "    if has_scaped == True:\n",
    "        continue\n",
    "    print(f'Processing recipe: {link}')\n",
    "    driver.get(link)\n",
    "    if f.page_exists(driver):\n",
    "        print(\"page doesn't exist\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        cookie = driver.find_element(By.ID,'onetrust-accept-btn-handler')\n",
    "        cookie.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    print('\\tGetting ingredients...')\n",
    "    ingredients = [i.text for i in driver.find_elements(By.CLASS_NAME,'ingredient')]\n",
    "    print('\\tGetting nutrition...')\n",
    "    nutrition = f.grab_nutrition(driver)\n",
    "    print('\\tGetting preparation...')\n",
    "    preparation = f.grab_preparation(driver)\n",
    "    print('\\tGetting date...')\n",
    "    date = f.grab_date(driver)\n",
    "    print('\\tGetting rating...')\n",
    "    rating = f.grab_recipe_rating(driver)\n",
    "    print('\\tGetting tags...')\n",
    "    try:\n",
    "        tags = f.get_tags(driver)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    print('\\tGetting number of comments...')\n",
    "    try: \n",
    "        number_of_comments = driver.find_element(By.CLASS_NAME,'tips-count-heading').text\n",
    "    except NoSuchElementException:\n",
    "        number_of_comments = \"0 TIPS\"\n",
    "    print('\\tGetting comments...')\n",
    "    if number_of_comments != \"0 TIPS\":\n",
    "        comments = f.grab_comments(driver)\n",
    "    else:\n",
    "        comments = []\n",
    "    \n",
    "    d = {'ingredients': ingredients,\n",
    "                            'nutrition': nutrition,\n",
    "                            'preparation': preparation,\n",
    "                            'date': date,\n",
    "                            'rating': rating,\n",
    "                            'tags': tags,\n",
    "                            'number_of_comments': number_of_comments,\n",
    "                            'comments': comments}\n",
    "    \n",
    "    f.save_and_remove_from_queue(link, d)\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending the Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
