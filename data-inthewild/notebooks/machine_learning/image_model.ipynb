{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "from images import create_train_test\n",
    "from images import to_tensorflow\n",
    "from images import augment_image\n",
    "from images import learning_curves\n",
    "from images import create_model\n",
    "from keras.utils import plot_model\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geotags soft f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../ml_models/images/image_model.yaml\", \"r\") as f:\n",
    "    image_model_config = yaml.safe_load(f)\n",
    "\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "\n",
    "data_path = \"../../data/processed/data.json\"\n",
    "#This splits the recepies into train and test. This doesn't actually load the features of the data\n",
    "X_train, X_val, y_train, y_val = create_train_test(image_model_config,data_path, \"geographical_tags_updated\")\n",
    "\n",
    "#This part loads in the data as tensorflow objects\n",
    "train_ds, val_ds, N_LABELS, y_val_bin, mlb = to_tensorflow(X_train, X_val, y_train, y_val, image_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation to the training dataset\n",
    "train_ds_augmented = train_ds.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Unbatch the augmented dataset\n",
    "train_ds = train_ds_augmented.unbatch()\n",
    "\n",
    "# Apply data augmentation to the training dataset\n",
    "val_ds_augmented = val_ds.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Unbatch the augmented dataset\n",
    "val_ds = val_ds_augmented.unbatch()\n",
    "\n",
    "model_path = f\"../../ml_models/images/\"\n",
    "number = str(len(os.listdir(model_path)))\n",
    "model_path += f\"final_model_{image_model_config['EPOCHS']}_epochs\"+ \".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(image_model_config, INPUT_SHAPE, N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=int(image_model_config[\"EPOCHS\"]),\n",
    "                    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.style as style\n",
    "rc = {'axes.facecolor':'white',\n",
    "      'axes.grid' : False,\n",
    "      'axes.spines.bottom': False,\n",
    "      'axes.spines.left': False,\n",
    "      'axes.spines.right': False,\n",
    "      'axes.spines.top': False,\n",
    "      'savefig.transparent': False}\n",
    "\n",
    "def learning_curves(history):\n",
    "    \"\"\"Plot the learning curves of loss and macro f1 score \n",
    "    for the training and validation datasets.\n",
    "    \n",
    "    Args:\n",
    "        history: history callback of fitting a tensorflow keras model \n",
    "    \"\"\"\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    macro_f1 = history.history['macro_f1']\n",
    "    val_macro_f1 = history.history['val_macro_f1']\n",
    "    \n",
    "    epochs = len(loss)\n",
    "\n",
    "    plt.rcParams.update(rc)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))  # Increase the figure height\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs+1), loss, label='Training Loss')\n",
    "    plt.plot(range(1, epochs+1), val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs+1), macro_f1, label='Training Macro F1-score')\n",
    "    plt.plot(range(1, epochs+1), val_macro_f1, label='Validation Macro F1-score')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Macro F1-score')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title('Training and Validation Macro F1-score')\n",
    "\n",
    "    #plt.subplots_adjust(hspace=0.2)  # Adjust the vertical space between subplots\n",
    "    plt.savefig(\"../../visualizations/images/training_analysis.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    return loss, val_loss, macro_f1, val_macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bce_losses, model_bce_val_losses, model_bce_macro_f1s, model_bce_val_macro_f1s = learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
