{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "#import missingno as msno\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 16:55:33.867412: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# we have saved the model, so now we just load it\n",
    "model = keras.models.load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test = pd.read_csv('Data/seq_labeling/opener_en-test-masked.conll',sep = '\\t',header = None,encoding = 'utf-8',comment = '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val = pd.read_csv('Data/seq_labeling/opener_en-dev.conll',sep = '\\t',header = None,encoding = 'utf-8',comment = '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard = pd.read_csv('Group3_hardsentences_converted.conll',sep = '\\t',header = None,encoding = 'utf-8',comment = '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/seq_labeling/opener_en-train.conll',sep = '\\t',header = None,encoding = 'utf-8',comment = '#')\n",
    "count_vec = CountVectorizer()\n",
    "count_vec.fit(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_of_lists(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    first = True\n",
    "    for elm in data.iterrows():\n",
    "        if elm[1][0] == 1:\n",
    "            if first != True:\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            x = []\n",
    "            y = []\n",
    "            first = False\n",
    "        x.append(elm[1][1])\n",
    "        y.append(elm[1][2])\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list_of_lists(X, max_len):\n",
    "    li = []\n",
    "\n",
    "    for elm in X:\n",
    "        t = []\n",
    "        for i in range(max_len):\n",
    "            if i >= len(elm):\n",
    "                t.append(count_vec.transform(['asdfasdfasdfasdfasdfsaf']).toarray().flatten() == 1)\n",
    "            else:\n",
    "                t.append(count_vec.transform([elm[i]]).toarray().flatten() == 1)\n",
    "        t = np.array(t)\n",
    "        li.append(t)\n",
    "    return np.array(li) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table = {\n",
    "    'O':0,\n",
    "    'B-Negative': 1,\n",
    "    'B-Positive': 2,\n",
    "    'I-Negative': 3,\n",
    "    'I-Positive':4,\n",
    "    'B-Negative|I-Negative': 5,\n",
    "    'B-Positive|I-Positive':6,\n",
    "    'I-Positive|B-Positive': 7,\n",
    "    'I-Positive|I-Positive': 8\n",
    "}\n",
    "\n",
    "def encode_labels(Y, lookup_labels, max_len):\n",
    "    li = []\n",
    "    for elm in Y:\n",
    "        t = []\n",
    "        counter = 0\n",
    "        for i in range(max_len):\n",
    "            if counter >= len(elm):\n",
    "                one_hot = np.zeros(9)\n",
    "                one_hot[0] = 1\n",
    "                t.append(np.zeros(9))\n",
    "            else:\n",
    "                one_hot = np.zeros(9)\n",
    "                one_hot[lookup_labels[elm[i]]] = 1\n",
    "                t.append(one_hot)\n",
    "            counter += 1\n",
    "        li.append(np.array(t))\n",
    "    return np.array(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_reverse = {\n",
    "    0:'O',\n",
    "    1:'B-Negative',\n",
    "    2:'B-Positive',\n",
    "    3:'I-Negative',\n",
    "    4:'I-Positive',\n",
    "    5:'B-Negative|I-Negative',\n",
    "    6:'B-Positive|I-Positive',\n",
    "    7:'I-Positive|B-Positive',\n",
    "    8:'I-Positive|I-Positive'\n",
    "}\n",
    "\n",
    "def dump_pred(pred, data_raw, input_path, output_path, lookup): \n",
    "    comments = []\n",
    "    with open(input_path) as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == '#':\n",
    "                comments.append(line)\n",
    "\n",
    "    with open(output_path, 'w', encoding='UTF-8') as f:\n",
    "        for sentence in range(len(comments)):\n",
    "            f.write(comments[sentence])\n",
    "            for word in range(len(pred[sentence])):\n",
    "                f.write(str(word + 1) + '\\t' + data_raw[sentence][word] + '\\t' + lookup[pred[sentence][word]] + '\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X, sentence_lengths):\n",
    "    pred = [[np.argmax(word) for word in sentence] for sentence in model.predict(X)]\n",
    "    pred_no_padding = [labels[:length] for labels, length in zip(pred, sentence_lengths)]\n",
    "    return pred_no_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have saved the model, so now we just load it\n",
    "model = keras.models.load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X_train_unencoded, Y_train_unencoded = make_list_of_lists(train)\n",
    "X_test_unencoded, Y_test_unencoded = make_list_of_lists(test)\n",
    "X_hard_unencoded, Y_hard_unencoded = make_list_of_lists(hard)\n",
    "\n",
    "\n",
    "# this value is for training, but will be treated as universal \n",
    "# ie. the longest sentece in training will be assumed to be longest overall\n",
    "\n",
    "max_len_train = max([len(elm) for elm in X_train_unencoded])\n",
    "X_test = encode_list_of_lists(X_test_unencoded, max_len_train)\n",
    "Y_test = encode_labels(Y_test_unencoded, lookup_table, max_len_train)\n",
    "\n",
    "X_hard = encode_list_of_lists(X_hard_unencoded,max_len_train)\n",
    "Y_hard = encode_labels(Y_hard_unencoded, lookup_table, max_len_train)\n",
    "\n",
    "# get predictions\n",
    "\n",
    "test_lengths = [len(sentence) for sentence in Y_test_unencoded]\n",
    "test_pred = make_predictions(model, X_test, test_lengths)\n",
    "\n",
    "hard_lengths = [len(sentence) for sentence in Y_hard_unencoded]\n",
    "hard_pred = make_predictions(model, X_hard, hard_lengths)\n",
    "hard_pred_flattened = sum(hard_pred, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "X_val_unencoded, Y_val_unencoded = make_list_of_lists(val)\n",
    "\n",
    "X_val = encode_list_of_lists(X_val_unencoded, max_len_train)\n",
    "Y_val = encode_labels(Y_val_unencoded, lookup_table, max_len_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions val\n",
    "\n",
    "val_lengths = [len(sentence) for sentence in Y_val_unencoded]\n",
    "val_pred = make_predictions(model, X_val, val_lengths)\n",
    "\n",
    "val_pred_flattened = sum(val_pred, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground truth val\n",
    "\n",
    "val_gt = [[np.argmax(word) for word in sentence] for sentence in Y_val]\n",
    "val_gt = [labels[:length] for labels, length in zip(val_gt, val_lengths)]\n",
    "val_gt_flattened = sum(val_gt, [])\n",
    "\n",
    "# hard sentences\n",
    "hard_gt = [[np.argmax(word) for word in sentence] for sentence in Y_hard]\n",
    "hard_gt = [labels[:length] for labels, length in zip(hard_gt, hard_lengths)]\n",
    "hard_gt_flattened = sum(hard_gt, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump_pred(test_pred, X_test_unencoded, 'Group3_hardsentences_converted.conll', 'hardsentences_predict.conll', lookup_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       638\n",
      "           1       0.08      0.07      0.08        56\n",
      "           2       0.25      0.17      0.20        94\n",
      "           3       0.25      0.17      0.20       143\n",
      "           4       0.23      0.14      0.18       202\n",
      "\n",
      "    accuracy                           0.49      1133\n",
      "   macro avg       0.28      0.26      0.27      1133\n",
      "weighted avg       0.44      0.49      0.46      1133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validation score\n",
    "\n",
    "print(classification_report(hard_gt_flattened, hard_pred_flattened))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = 'Group3_hardsentences_converted.conll'\n",
    "\n",
    "numSents = 0\n",
    "\n",
    "for lineIdx, line in enumerate(open(inputPath)):\n",
    "    if line[0] == '#':\n",
    "        continue\n",
    "    if len(line) < 2:\n",
    "        numSents += 1\n",
    "        continue\n",
    "    tok = line.strip().split('\\t')\n",
    "    if len(tok) < 3:\n",
    "        print(str(lineIdx) + ': Not all columns defined: ' + line)\n",
    "        exit(1)\n",
    "    if not tok[0].isdigit():\n",
    "        print(str(lineIdx) + ': Invalid word index found: ' + line)\n",
    "        exit(1)\n",
    "    if len(tok[1].strip()) == 0:\n",
    "        print(str(lineIdx) + ': Empty token: ' + line)\n",
    "        exit(1)        \n",
    "    if tok[2] not in ['B-Positive', 'I-Positive', 'O', 'B-Negative', 'I-Negative']:\n",
    "        print(str(lineIdx) + ': Label is invalid: ' + line)\n",
    "        exit(1)\n",
    "        \n",
    "if numSents+1 < 50:\n",
    "    print('Too little instances(' + str(numSents) + '), please generate more')\n",
    "if numSents > 1000:\n",
    "    print('Too many instances(' + str(numSents) + '), please generate more')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
