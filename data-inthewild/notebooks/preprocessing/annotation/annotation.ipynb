{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "from random import seed, shuffle, sample\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might need to do this in an external terminal, if it throws a permissions error\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation of ingredients \n",
    "\n",
    "This notebook includes the annotation and prediction of ingredients.\n",
    "\n",
    "The process is structured in the following way:\n",
    "\n",
    "- Extracting a sample of the raw ingredient data from the dataset, making some preliminary predictions, and saving it as _.jsonl_ for use in the annotation software _Doccano_. The preliminary annotations are made with another model, that we did not end up using, and serve to ease the annotation process.\n",
    "- (not in the notebook) Annotating the data using _Doccano_\n",
    "- Constructing a training dataset from our annotations, using a majority vote system (here we only use 3 annotators).\n",
    "- Training a model with _spacy_, using on these training data.\n",
    "- Computing labels for the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing preliminary annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '../../../data/raw/data_raw.json'\n",
    "\n",
    "LABELING_MODEL_PATH = \"PREVIOUS MODEL INSERT PATH HERE (not needed anymore)\"\n",
    "\n",
    "ANNOTATION_FOLDER = '../../../data/interim/annotation/'\n",
    "TO_ANNOTATE = ANNOTATION_FOLDER + \"TO_ANNOTATE.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL RELIES ON A PREVIOUS MODEL, WHICH WE HAVE NOT SAVED.\n",
    "# THE OUTPUT IS SAVED IN A FILE IN THE DATA DIRECTORY -- SO IT DOES NOT NEED TO BE RUN\n",
    "\n",
    "\n",
    "with open(RAW_DATA_PATH, 'r', encoding = 'utf8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# we sample 30 recipes\n",
    "seed(69)\n",
    "keys = sample(list(data.keys()), 30)\n",
    "\n",
    "ingredients = []\n",
    "\n",
    "for key in keys:\n",
    "    ingredients.extend(data[key]['ingredients'])\n",
    "\n",
    "# we trained this model with smaller amount of data\n",
    "nlp = spacy.load(LABELING_MODEL_PATH)\n",
    "\n",
    "outs = []\n",
    "\n",
    "for ingredient in ingredients:\n",
    "\n",
    "    doc = nlp(ingredient)\n",
    "\n",
    "    label = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        label.append([ent.start_char, ent.end_char, 'ingredient'])\n",
    "\n",
    "    outs.append({\"text\": ingredient, \n",
    "                 \"label\": label})\n",
    "    \n",
    "with open(ANNOTATION_FOLDER + TO_ANNOTATE, 'w', encoding=\"utf8\") as file:\n",
    "    for out in outs:\n",
    "        file.write(json.dumps(out, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation\n",
    "\n",
    "_Done in Doccano_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate combined training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_ANNOTATORS = 3\n",
    "COMBINED_PATH = ANNOTATION_FOLDER + 'annotations/COMBINED.jsonl'\n",
    "\n",
    "ANNOTATED_FILES = [\n",
    "    'bogdan.jsonl',\n",
    "    'gino.jsonl',\n",
    "    'veron.jsonl'\n",
    "]\n",
    "\n",
    "TRAIN_PATH = ANNOTATION_FOLDER + \"spacy/train.spacy\"\n",
    "DEV_PATH = ANNOTATION_FOLDER + \"spacy/dev.spacy\"\n",
    "TEST_PATH = ANNOTATION_FOLDER + \"spacy/test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_lists = []\n",
    "\n",
    "for annotator_file in ANNOTATED_FILES:\n",
    "    with open(ANNOTATION_FOLDER + 'annotations/' + annotator_file, 'r', encoding='utf-8') as file:\n",
    "        annotator_list = [\n",
    "            json.loads(line)\n",
    "            for line in file.readlines()\n",
    "        ]\n",
    "        annotator_lists.append(sorted(annotator_list, key=lambda x: x['id']))\n",
    "\n",
    "# we only use 3 of the annotators, \n",
    "# because we had issues with majority voting with an even number of annotators\n",
    "\n",
    "final_annotations = []\n",
    "\n",
    "for annotations in zip(*annotator_lists[:3]):\n",
    "    \n",
    "    labels = [\n",
    "        (label[0], label[1])\n",
    "        for annotation in annotations\n",
    "            for label in annotation['label']\n",
    "    ]\n",
    "\n",
    "    to_keep = [\n",
    "        label\n",
    "        for label, count\n",
    "            in Counter(labels).items()\n",
    "        if count / NO_ANNOTATORS > 0.5\n",
    "    ]\n",
    "\n",
    "    final_annotations.append(\n",
    "        {\n",
    "            'text': annotations[0]['text'],\n",
    "            'label': [\n",
    "                [label[0], label[1], 'ingredient']\n",
    "                for label in to_keep\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "with open(COMBINED_PATH, 'w', encoding='utf-8') as file:\n",
    "    for annotation in final_annotations:\n",
    "        file.write(json.dumps(annotation, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(outfile_name, annotations):\n",
    "    '''\n",
    "    takes jsonl-data (annotations) as saves it as a spacy binary dataset\n",
    "    '''\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "\n",
    "    for annotation in annotations:\n",
    "        doc = nlp(annotation[\"text\"])\n",
    "        ents = []\n",
    "        for start, end, label in annotation['label']:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span != None:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "\n",
    "    db.to_disk(outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COMBINED_PATH, 'r', encoding='utf-8') as f:\n",
    "    final_annotations = [\n",
    "        json.loads(line)\n",
    "        for line \n",
    "            in f.readlines()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(100)\n",
    "shuffle(final_annotations)\n",
    "\n",
    "train_i = len(final_annotations) - (len(final_annotations) // 3)\n",
    "dev_i = len(final_annotations) - (len(final_annotations) // 6)\n",
    "\n",
    "train = final_annotations[:train_i]\n",
    "dev = final_annotations[train_i:dev_i]\n",
    "test = final_annotations[dev_i:]\n",
    "\n",
    "make_data(TRAIN_PATH, train)\n",
    "make_data(DEV_PATH, dev)\n",
    "\n",
    "with open(TEST_PATH, 'w', encoding='utf-8') as f:\n",
    "    for annotation in test:\n",
    "        f.write(json.dumps(annotation, ensure_ascii=False))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training annotator model\n",
    "\n",
    "_Done with spacy in shell_\n",
    "\n",
    "_python -m spacy train ml_models/annotation/config.cfg --output ml_models/annotation/models_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making synthetic annotations using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = ANNOTATION_FOLDER + 'data.json'\n",
    "MODEL_PATH = '../../../ml_models/annotation/models/model-best/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RAW_DATA_PATH, 'r', encoding = 'utf8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "keys = data.keys()\n",
    "\n",
    "nlp = spacy.load(MODEL_PATH)\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for key in keys:\n",
    "    ingredients = data[key]['ingredients']\n",
    "    data[key]['ingredient_annotations'] = []\n",
    "    for ingredient in ingredients:\n",
    "        doc = nlp(ingredient)\n",
    "        for ent in doc.ents:\n",
    "            data[key]['ingredient_annotations'].append(' '.join([lem.lemmatize(token.text) for token in ent]).lower())\n",
    "\n",
    "with open(OUT_PATH, 'wb') as f:\n",
    "    f.write(json.dumps(data, indent = 4, ensure_ascii=False).encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "We test on the test data using f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(MODEL_PATH)\n",
    "\n",
    "with open(TEST_PATH, 'r', encoding='utf-8') as f:\n",
    "    test_data = [\n",
    "        json.loads(ingr)\n",
    "        for ingr in f.readlines()\n",
    "    ]\n",
    "\n",
    "ground_truth = [\n",
    "    [\n",
    "        ingr['text'][label[0]:label[1]] \n",
    "        for label \n",
    "            in ingr['label']\n",
    "    ]\n",
    "    \n",
    "    for ingr in test_data\n",
    "]\n",
    "\n",
    "pred = [\n",
    "    [\n",
    "        ent.text\n",
    "        for ent\n",
    "            in nlp(ingr['text']).ents\n",
    "    ]\n",
    "    \n",
    "    for ingr in test_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = MultiLabelBinarizer().fit(pred + ground_truth)\n",
    "f1_score(binarizer.transform(pred), binarizer.transform(ground_truth), average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
